1
00:00:00,000 --> 00:00:04,470
[音乐]

2
00:00:04,480 --> 00:00:06,869
这是三，写得很草率

3
00:00:06,869 --> 00:00:06,879
这是三，写得马虎

4
00:00:06,879 --> 00:00:08,470
这是三，写得草率，渲染得极低

5
00:00:08,470 --> 00:00:08,480
并以极低的分辨率渲染

6
00:00:08,480 --> 00:00:11,270
你的作品分辨率极低，只有 28x28 像素。

7
00:00:11,270 --> 00:00:11,280
分辨率为 28x28 像素

8
00:00:11,280 --> 00:00:13,390
但你的大脑不难将其识别为一个"......"。

9
00:00:13,390 --> 00:00:13,400
但你的大脑不难将其识别为

10
00:00:13,400 --> 00:00:15,470
我希望你们花一点时间，把它看成是一个

11
00:00:15,470 --> 00:00:15,480
三，我要你花一点时间来

12
00:00:15,480 --> 00:00:17,630
我希望你们花一点时间来体会一下，大脑

13
00:00:17,630 --> 00:00:17,640
我希望你们花一点时间

14
00:00:17,640 --> 00:00:20,429
大脑能如此毫不费力地做到这一点是多么疯狂

15
00:00:20,429 --> 00:00:20,439
我是说

16
00:00:20,439 --> 00:00:22,710
我的意思是，这和这也可以被识别为

17
00:00:22,710 --> 00:00:22,720
我的意思是

18
00:00:22,720 --> 00:00:25,070
我的意思是说，这个和这个也可以被识别为这个和这个，尽管它们的具体价值

19
00:00:25,070 --> 00:00:25,080
三者的具体价值

20
00:00:25,080 --> 00:00:27,390
尽管每个像素的具体值与一个像素的具体值有很大的不同，但我们还是可以将其识别为三 个像素。

21
00:00:27,390 --> 00:00:27,400
每个像素的具体数值

22
00:00:27,400 --> 00:00:30,070
尽管每个像素的具体值与不同图像的具体值有很大差异，但仍能识别为三幅图像。

23
00:00:30,070 --> 00:00:30,080
图像到下一个图像的特定感光

24
00:00:30,080 --> 00:00:31,870
在你的眼睛中，对光敏感的细胞对你的眼睛中对光敏感的细胞对你的眼睛中对光敏感的细胞对你的眼睛中对光敏感的细胞

25
00:00:31,870 --> 00:00:31,880
眼睛中的敏感细胞

26
00:00:31,880 --> 00:00:34,389
当你看到这三幅图像时，你眼睛中的敏感细胞会发生反应。

27
00:00:34,389 --> 00:00:34,399
当你看到这三个非常

28
00:00:34,399 --> 00:00:35,990
当你看到这三点时发射的信号与你看到这三点时发射的信号有很大不同

29
00:00:35,990 --> 00:00:36,000
不同

30
00:00:36,000 --> 00:00:38,630
不同，但其中的某些东西

31
00:00:38,630 --> 00:00:38,640
看到这个三，但你的

32
00:00:38,640 --> 00:00:41,069
但在你疯狂聪明的视觉皮层里

33
00:00:41,069 --> 00:00:41,079
你疯狂聪明的视觉皮层

34
00:00:41,079 --> 00:00:43,389
你那疯狂聪明的视觉皮层 把这些看成是相同的

35
00:00:43,389 --> 00:00:43,399
把这些看成是相同的

36
00:00:43,399 --> 00:00:45,709
你那疯狂聪明的视觉皮层中的某种东西

37
00:00:45,709 --> 00:00:45,719
同时识别其他

38
00:00:45,719 --> 00:00:49,110
把其他图像当作自己的独特想法

39
00:00:49,110 --> 00:00:49,120
将其他图像视为自己的独特想法

40
00:00:49,120 --> 00:00:51,470
但如果我告诉你，嘿，坐下来写吧

41
00:00:51,470 --> 00:00:51,480
但如果我告诉你，嘿，坐下来写

42
00:00:51,480 --> 00:00:54,349
但是，如果我告诉你，嘿，坐下来，为我写一个程序，接收一个网格的

43
00:00:54,349 --> 00:00:54,359
如果我告诉你

44
00:00:54,359 --> 00:00:57,549
这样输入一个 28x28 像素的网格，然后输出一个

45
00:00:57,549 --> 00:00:57,559
像这样输入一个 28x28 像素的网格，然后输出一个

46
00:00:57,559 --> 00:01:00,349
然后输出一个介于 0 和 10 之间的单个数字。

47
00:01:00,349 --> 00:01:00,359
输出一个介于 0 和 10 之间的单个数字

48
00:01:00,359 --> 00:01:02,950
它还会输出一个介于 0 和 10 之间的单个数字，告诉你它认为的数字是多少。

49
00:01:02,950 --> 00:01:02,960
它认为数字是多少？

50
00:01:02,960 --> 00:01:05,030
你认为数字是多少？

51
00:01:05,030 --> 00:01:05,040
任务从微不足道到

52
00:01:05,040 --> 00:01:07,590
除非你一直在做，否则任务就会从琐碎到令人生畏的困难。

53
00:01:07,590 --> 00:01:07,600
令人生畏的困难，除非你一直

54
00:01:07,600 --> 00:01:09,230
除非你一直生活在岩石之下，否则就很难做到。

55
00:01:09,230 --> 00:01:09,240
我想我很难

56
00:01:09,240 --> 00:01:10,830
我想我几乎不需要激励相关性，也不需要激励自己。

57
00:01:10,830 --> 00:01:10,840
我认为，我几乎不需要激励自己

58
00:01:10,840 --> 00:01:12,230
我认为，我几乎不需要激发机器学习的相关性和重要性。

59
00:01:12,230 --> 00:01:12,240
机器学习的重要性

60
00:01:12,240 --> 00:01:14,190
机器学习和神经网络对当前和未来的重要性

61
00:01:14,190 --> 00:01:14,200
神经网络对当前和未来的重要性

62
00:01:14,200 --> 00:01:16,149
但我想在这里做的是

63
00:01:16,149 --> 00:01:16,159
未来，但我想在这里做的是

64
00:01:16,159 --> 00:01:18,270
但我想在这里做的是，向你们展示神经网络究竟是什么。

65
00:01:18,270 --> 00:01:18,280
向你们展示神经网络究竟是什么

66
00:01:18,280 --> 00:01:20,670
我想在这里做的是，向你们展示神经网络实际上是什么。

67
00:01:20,670 --> 00:01:20,680
在没有背景的情况下

68
00:01:20,680 --> 00:01:22,670
帮助直观地了解它在做什么，而不是把它作为一个

69
00:01:22,670 --> 00:01:22,680
在没有任何背景的情况下，神经网络可以帮助你直观地了解它在做什么。

70
00:01:22,680 --> 00:01:25,350
我希望，这不是一句流行语，而是一门数学。

71
00:01:25,350 --> 00:01:25,360
但我希望它是数学的一部分

72
00:01:25,360 --> 00:01:26,910
我的希望是，你会觉得

73
00:01:26,910 --> 00:01:26,920
我的希望是

74
00:01:26,920 --> 00:01:29,310
我的希望是，你会觉得结构本身是有动力的，并且

75
00:01:29,310 --> 00:01:29,320
结构本身是有动力的

76
00:01:29,320 --> 00:01:30,830
结构本身是有动力的，而且感觉自己知道当

77
00:01:30,830 --> 00:01:30,840
你知道这意味着什么吗？

78
00:01:30,840 --> 00:01:32,710
当你读到或听到有关神经元的信息时，你会觉得自己知道这意味着什么。

79
00:01:32,710 --> 00:01:32,720
你读过或听说过神经网络

80
00:01:32,720 --> 00:01:35,510
你读到或听到一个神经网络在学习这个

81
00:01:35,510 --> 00:01:35,520
网络引语学习

82
00:01:35,520 --> 00:01:37,069
你读到或听到关于神经网络的信息

83
00:01:37,069 --> 00:01:37,079
视频将致力于

84
00:01:37,079 --> 00:01:38,749
视频将专注于其中的结构部分和

85
00:01:38,749 --> 00:01:38,759
结构部分

86
00:01:38,759 --> 00:01:39,830
结构部分，而下面的内容将涉及

87
00:01:39,830 --> 00:01:39,840
下面的视频将讨论

88
00:01:39,840 --> 00:01:41,990
我们要做的是，把我们要做的东西放在视频中。

89
00:01:41,990 --> 00:01:42,000
学习我们要做的是什么？

90
00:01:42,000 --> 00:01:43,950
我们要做的是把能够学习的神经网络放在一起

91
00:01:43,950 --> 00:01:43,960
一个能够学习的神经网络

92
00:01:43,960 --> 00:01:48,590
学习识别手写数字的神经网络。

93
00:01:48,600 --> 00:01:50,870
这是一个有点经典的

94
00:01:50,870 --> 00:01:50,880
这是一个有点经典的

95
00:01:50,880 --> 00:01:52,830
这是一个有点经典的手写数字例子。

96
00:01:52,830 --> 00:01:52,840
介绍主题的例子

97
00:01:52,840 --> 00:01:54,350
我很乐意维持现状。

98
00:01:54,350 --> 00:01:54,360
我乐于维持现状

99
00:01:54,360 --> 00:01:55,830
我很高兴在这里维持现状，因为在这两篇文章的最后

100
00:01:55,830 --> 00:01:55,840
在这里，因为在两个

101
00:01:55,840 --> 00:01:57,389
因为在这两段视频的最后，我想向大家介绍几段

102
00:01:57,389 --> 00:01:57,399
视频

103
00:01:57,399 --> 00:01:59,310
我想告诉大家一些好的资源，在那里你可以学到更多的东西。

104
00:01:59,310 --> 00:01:59,320
你可以学到更多知识的好资源

105
00:01:59,320 --> 00:02:01,029
好的资源，在那里你可以学到更多，在那里你可以下载代码，在那里你可以学到更多，在那里你可以下载代码，在那里你可以学到更多。

106
00:02:01,029 --> 00:02:01,039
以及在哪里可以下载

107
00:02:01,039 --> 00:02:04,109
以及在哪里可以下载实现这些功能的代码，并自己进行操作

108
00:02:04,109 --> 00:02:04,119
在你自己的电脑上运行

109
00:02:04,119 --> 00:02:07,069
在你自己的电脑上玩这个游戏

110
00:02:07,069 --> 00:02:07,079
计算机

111
00:02:07,079 --> 00:02:08,990
近几年来，神经网络的变种越来越多。

112
00:02:08,990 --> 00:02:09,000
神经网络

113
00:02:09,000 --> 00:02:10,949
近年来，神经网络的研究出现了热潮。

114
00:02:10,949 --> 00:02:10,959
研究热潮

115
00:02:10,959 --> 00:02:13,309
这些变体的研究也在蓬勃发展。

116
00:02:13,309 --> 00:02:13,319
这些变体

117
00:02:13,319 --> 00:02:15,470
但在这两个介绍性视频中，你和我只是

118
00:02:15,470 --> 00:02:15,480
你和我只是

119
00:02:15,480 --> 00:02:17,110
在这两段介绍性视频中，你和我只是在看最简单的普通

120
00:02:17,110 --> 00:02:17,120
你和我只是要看看最简单的

121
00:02:17,120 --> 00:02:19,790
最简单的普通香草形式，不加任何装饰。

122
00:02:19,790 --> 00:02:19,800
不加任何修饰的香草形式

123
00:02:19,800 --> 00:02:22,110
这是实现这些目标的必要先决条件。

124
00:02:22,110 --> 00:02:22,120
是一种必要的先决条件

125
00:02:22,120 --> 00:02:23,509
要理解任何更强大的力量，这是必要的先决条件。

126
00:02:23,509 --> 00:02:23,519
了解更强大的现代变体

127
00:02:23,519 --> 00:02:25,910
现代变体，相信我，它仍然是

128
00:02:25,910 --> 00:02:25,920
相信我，它仍然

129
00:02:25,920 --> 00:02:27,750
相信我，它仍然有足够的复杂性让我们去包装。

130
00:02:27,750 --> 00:02:27,760
我们要做的，就是把它变得更加复杂。

131
00:02:27,760 --> 00:02:29,910
有很多复杂性需要我们去思考，但即使在这种情况下

132
00:02:29,910 --> 00:02:29,920
但即使在这种情况下

133
00:02:29,920 --> 00:02:31,990
但即使是这种最简单的形式，它也能学会识别

134
00:02:31,990 --> 00:02:32,000
在这种情况下，它也能学会识别手写体。

135
00:02:32,000 --> 00:02:33,990
但即使是这种最简单的形式，它也能学会识别手写数字。

136
00:02:33,990 --> 00:02:34,000
手写数字是一种漂亮的

137
00:02:34,000 --> 00:02:36,430
对计算机来说，能够识别手写数字是一件很酷的事情。

138
00:02:36,430 --> 00:02:36,440
电脑能识别手写数字

139
00:02:36,440 --> 00:02:39,030
同时，你还会看到它是如何实现的。

140
00:02:39,030 --> 00:02:39,040
同时，你还会看到如何

141
00:02:39,040 --> 00:02:40,910
同时，你还会看到它是如何辜负了一些希望的

142
00:02:40,910 --> 00:02:40,920
它确实辜负了一些人的希望

143
00:02:40,920 --> 00:02:42,550
它确实辜负了我们的一些希望

144
00:02:42,550 --> 00:02:42,560
希望

145
00:02:42,560 --> 00:02:45,430
顾名思义，就是神经网络

146
00:02:45,430 --> 00:02:45,440
顾名思义，神经网络

147
00:02:45,440 --> 00:02:47,790
顾名思义，神经网络的灵感来自大脑，但让我们

148
00:02:47,790 --> 00:02:47,800
神经网络的灵感来自大脑，但让我们

149
00:02:47,800 --> 00:02:49,990
但是，让我们来分解一下神经元是什么？

150
00:02:49,990 --> 00:02:50,000
什么是神经元？

151
00:02:50,000 --> 00:02:52,470
它们在什么意义上联系在一起？

152
00:02:52,470 --> 00:02:52,480
它们在什么意义上联系在一起

153
00:02:52,480 --> 00:02:55,110
现在，当我说神经元时，我想

154
00:02:55,110 --> 00:02:55,120
现在，当我说神经元时，我想要的一切

155
00:02:55,120 --> 00:02:57,309
现在，当我说神经元时，我想让你思考的是一个能让你思考的东西。

156
00:02:57,309 --> 00:02:57,319
我想让你思考的是

157
00:02:57,319 --> 00:02:59,830
你要考虑的是一个能容纳一个数字的东西，特别是一个介于 Z

158
00:02:59,830 --> 00:02:59,840
Z 之间的一个数

159
00:02:59,840 --> 00:03:02,789
0 和 1 之间的一个数。

160
00:03:02,789 --> 00:03:02,799
0 和 1 之间的数。

161
00:03:02,799 --> 00:03:05,789
0 和 1 之间的数字。

162
00:03:05,789 --> 00:03:05,799
例如，网络以

163
00:03:05,799 --> 00:03:07,949
例如，网络一开始有一堆神经元，每堆神经元对应一个 "0 "和 "1"。

164
00:03:07,949 --> 00:03:07,959
与每个神经元相对应的一堆神经元

165
00:03:07,959 --> 00:03:11,750
与输入图像中 28 * 28 像素的每个像素相对应的神经元群

166
00:03:11,750 --> 00:03:11,760
输入图像的 28 * 28 像素中的每个像素

167
00:03:11,760 --> 00:03:14,910
输入图像的 28 * 28 像素中的每一个像素对应的神经元群。

168
00:03:14,910 --> 00:03:14,920
共 784 个神经元，每个神经元

169
00:03:14,920 --> 00:03:17,229
这些神经元中的每一个都有一个数字，表示

170
00:03:17,229 --> 00:03:17,239
的数字代表

171
00:03:17,239 --> 00:03:20,070
这些神经元中的每个神经元都持有一个数字，该数字代表相应图像的灰度值。

172
00:03:20,070 --> 00:03:20,080
相应像素的灰度值

173
00:03:20,080 --> 00:03:22,869
相应像素的灰度值，黑色像素的灰度值范围为零

174
00:03:22,869 --> 00:03:22,879
黑色像素的灰度值范围为零

175
00:03:22,879 --> 00:03:25,949
黑色像素的灰度值为零，白色像素的灰度值为一。

176
00:03:25,949 --> 00:03:25,959
白色像素的最大值为 1

177
00:03:25,959 --> 00:03:27,990
在神经元内部，这个数字被称为它的

178
00:03:27,990 --> 00:03:28,000
神经元内部的这一数字称为其

179
00:03:28,000 --> 00:03:29,949
神经元内部的这一数字称为其激活度，你可能得到的图像称为其激活度。

180
00:03:29,949 --> 00:03:29,959
激活和你可能拥有的图像

181
00:03:29,959 --> 00:03:31,910
你可能会想到的图像是，每个神经元都被点亮。

182
00:03:31,910 --> 00:03:31,920
在这里，每个神经元都被点亮

183
00:03:31,920 --> 00:03:35,589
这里要注意的是，当每个神经元的激活程度较高时，它就会被点亮。

184
00:03:35,589 --> 00:03:35,599
当激活的神经元数目较高时

185
00:03:35,599 --> 00:03:39,350
因此，所有这 784 个神经元都会产生一个 "数字"。

186
00:03:39,350 --> 00:03:39,360
因此，所有这 784 个神经元都会产生 "数字"。

187
00:03:39,360 --> 00:03:45,309
因此，这 784 个神经元组成了我们的第一层网络。

188
00:03:45,319 --> 00:03:47,589
网络现在跳转到最后一层

189
00:03:47,589 --> 00:03:47,599
网络现在跳转到最后一层

190
00:03:47,599 --> 00:03:49,990
现在跳转到最后一层，每层有 10 个神经元。

191
00:03:49,990 --> 00:03:50,000
每层有 10 个神经元

192
00:03:50,000 --> 00:03:52,190
每层有 10 个神经元，每个神经元代表一个数字，每个数字代表一个神经元。

193
00:03:52,190 --> 00:03:52,200
代表其中一位数字

194
00:03:52,200 --> 00:03:54,750
这些神经元中又有一些神经元被激活。

195
00:03:54,750 --> 00:03:54,760
激活这些神经元

196
00:03:54,760 --> 00:03:56,830
在这些神经元中再次激活一些介于 0 和 1 之间的数字。

197
00:03:56,830 --> 00:03:56,840
介于 0 和 1 之间的数字

198
00:03:56,840 --> 00:03:59,149
介于 0 和 1 之间的数字代表了系统思考的程度

199
00:03:59,149 --> 00:03:59,159
代表系统认为

200
00:03:59,159 --> 00:04:01,470
代表了系统认为某个图像与某个神经元对应的程度。

201
00:04:01,470 --> 00:04:01,480
某幅图像与一个

202
00:04:01,480 --> 00:04:04,149
还有几层意思是，系统认为某个图像与某个数字相对应。

203
00:04:04,149 --> 00:04:04,159
给定数字也有几个层次

204
00:04:04,159 --> 00:04:06,589
在给定数字和给定图像之间还有几层，称为 "隐藏层"。

205
00:04:06,589 --> 00:04:06,599
在这两层之间，还有一层叫做 "隐藏层"。

206
00:04:06,599 --> 00:04:08,670
在这两层之间，还有一层叫做 "隐藏层"，目前应该只是

207
00:04:08,670 --> 00:04:08,680
目前应该只是

208
00:04:08,680 --> 00:04:10,869
目前应该只是一个巨大的问号，地球上怎么会有这样的人

209
00:04:10,869 --> 00:04:10,879
一个巨大的问号

210
00:04:10,879 --> 00:04:12,789
地球上识别数字的过程是如何进行的？

211
00:04:12,789 --> 00:04:12,799
这个识别数字的过程

212
00:04:12,799 --> 00:04:14,869
这个识别数字的过程将如何在这个网络中处理？

213
00:04:14,869 --> 00:04:14,879
这个网络将如何处理？

214
00:04:14,879 --> 00:04:17,229
在这个网络中，我选择了两个隐藏层，每个隐藏层有 16 个数字。

215
00:04:17,229 --> 00:04:17,239
选择两个隐藏层，每层 16 个

216
00:04:17,239 --> 00:04:19,670
我选择了两个隐藏层，每个隐藏层有 16 个神经元。

217
00:04:19,670 --> 00:04:19,680
神经元。

218
00:04:19,680 --> 00:04:21,789
老实说，我是随意选择的。

219
00:04:21,789 --> 00:04:21,799
老实说，我选择了

220
00:04:21,799 --> 00:04:23,110
老实说，我根据自己的需要选择了两层。

221
00:04:23,110 --> 00:04:23,120
我选择了两层

222
00:04:23,120 --> 00:04:25,270
我选择了两层，因为我想在短时间内激发结构的动力。

223
00:04:25,270 --> 00:04:25,280
我选择了两层。

224
00:04:25,280 --> 00:04:27,310
我选择了两层，因为我想在短时间内激发结构的积极性。

225
00:04:27,310 --> 00:04:27,320
这只是个不错的数字

226
00:04:27,320 --> 00:04:29,310
在实践中，这只是一个适合在屏幕上显示的好数字。

227
00:04:29,310 --> 00:04:29,320
在实践中

228
00:04:29,320 --> 00:04:30,990
在实践中，屏幕上还有很多实验空间。

229
00:04:30,990 --> 00:04:31,000
有很大的实验空间

230
00:04:31,000 --> 00:04:33,430
在这里，我们可以用一种特定的结构，即"...... "的方式进行实验。

231
00:04:33,430 --> 00:04:33,440
这里的特定结构

232
00:04:33,440 --> 00:04:35,510
在这里，网络以一种特定的结构运行，以一种激活方式运行。

233
00:04:35,510 --> 00:04:35,520
网络以一种激活方式运行

234
00:04:35,520 --> 00:04:37,909
网络在一个层中的激活度决定了该层的激活度。

235
00:04:37,909 --> 00:04:37,919
层的激活度决定下一层的激活度

236
00:04:37,919 --> 00:04:40,070
确定下一层的激活度，当然还有下一层的核心。

237
00:04:40,070 --> 00:04:40,080
网络的核心

238
00:04:40,080 --> 00:04:42,350
当然，网络的核心是信息处理。

239
00:04:42,350 --> 00:04:42,360
作为信息处理机制的网络

240
00:04:42,360 --> 00:04:45,189
网络作为一种信息处理机制，其核心在于它是如何处理信息的。

241
00:04:45,189 --> 00:04:45,199
网络是信息处理的核心。

242
00:04:45,199 --> 00:04:46,909
这就是为什么我们要把网络作为信息处理的核心。

243
00:04:46,909 --> 00:04:46,919
这就是为什么我们要把网络作为信息处理机制的原因。

244
00:04:46,919 --> 00:04:49,390
激活下一层。

245
00:04:49,390 --> 00:04:49,400
下一层的激活。

246
00:04:49,400 --> 00:04:51,790
松散地类似于"'......

247
00:04:51,790 --> 00:04:51,800
松散地类比于在"......

248
00:04:51,800 --> 00:04:53,990
与生物神经元网络中的一些神经元的激活方式大致相同。

249
00:04:53,990 --> 00:04:54,000
神经元的生物网络

250
00:04:54,000 --> 00:04:56,350
神经元的生物网络中，一些神经元群的发射导致某些

251
00:04:56,350 --> 00:04:56,360
在神经元的生物网络中，某些神经元群

252
00:04:56,360 --> 00:04:58,550
现在，我所处的网络，就是这样的。

253
00:04:58,550 --> 00:04:58,560
现在我的网络

254
00:04:58,560 --> 00:05:00,590
现在，我在这里展示的网络已经被训练为

255
00:05:00,590 --> 00:05:00,600
这里显示的网络

256
00:05:00,600 --> 00:05:02,430
让我向你们展示一下

257
00:05:02,430 --> 00:05:02,440
让我向你们展示

258
00:05:02,440 --> 00:05:04,550
让我告诉你我说的是什么意思 意思是如果你给它喂食

259
00:05:04,550 --> 00:05:04,560
我的意思是，如果你输入

260
00:05:04,560 --> 00:05:08,230
我的意思是，这意味着，如果你喂 在图像中点亮所有784个神经元

261
00:05:08,230 --> 00:05:08,240
在一幅图像中点亮所有 784 个神经元

262
00:05:08,240 --> 00:05:10,350
输入层的所有 784 个神经元。

263
00:05:10,350 --> 00:05:10,360
输入层的所有 784 个神经元

264
00:05:10,360 --> 00:05:12,749
输入层的所有 784 个神经元，根据图像中每个像素的亮度

265
00:05:12,749 --> 00:05:12,759
图像中每个像素的亮度

266
00:05:12,759 --> 00:05:15,310
图像中每个像素的亮度激活模式会导致某些神经元的亮度降低，而另一些神经元的亮度则会降低。

267
00:05:15,310 --> 00:05:15,320
该激活模式会导致一些

268
00:05:15,320 --> 00:05:17,550
该激活模式会导致下一层出现某种非常特殊的模式

269
00:05:17,550 --> 00:05:17,560
下一层中非常特殊的模式

270
00:05:17,560 --> 00:05:18,990
下一层中非常特殊的模式会导致一层中的某些模式

271
00:05:18,990 --> 00:05:19,000
导致后一层中的某种模式

272
00:05:19,000 --> 00:05:20,790
在下一层中产生某种模式，在上一层中产生某种模式，在下一层中产生某种模式，在上一层中产生某种模式，在下一层中产生某种模式

273
00:05:20,790 --> 00:05:20,800
在它之后的一层中，最终会产生一些

274
00:05:20,800 --> 00:05:22,909
最后，在输出层中产生一些模式，而在输出层中产生的模式又会对下一层产生影响。

275
00:05:22,909 --> 00:05:22,919
输出层的模式和

276
00:05:22,919 --> 00:05:25,670
输出层中最亮的神经元是

277
00:05:25,670 --> 00:05:25,680
输出层最亮的神经元是

278
00:05:25,680 --> 00:05:27,830
可以说，输出层中最亮的神经元就是网络的选择。

279
00:05:27,830 --> 00:05:27,840
网络的选择

280
00:05:27,840 --> 00:05:32,469
可以说，网络选择了这幅图代表的数字

281
00:05:32,479 --> 00:05:34,270
在跳转到如何计算之前

282
00:05:34,270 --> 00:05:34,280
的数学计算之前

283
00:05:34,280 --> 00:05:36,270
在计算这一层如何影响下一层或这一层如何影响下一层之前

284
00:05:36,270 --> 00:05:36,280
一层是如何影响下一层的？

285
00:05:36,280 --> 00:05:38,710
让我们来谈谈为什么培训能起作用。

286
00:05:38,710 --> 00:05:38,720
我们来谈谈为什么分层培训是合理的。

287
00:05:38,720 --> 00:05:40,950
让我们来谈谈为什么分层培训是合理的。

288
00:05:40,950 --> 00:05:40,960
为什么期待分层培训是合理的？

289
00:05:40,960 --> 00:05:43,110
我们只想谈谈，为什么期待一个分层结构的行为是合理的？

290
00:05:43,110 --> 00:05:43,120
这样的结构

291
00:05:43,120 --> 00:05:45,350
我们在这里期待什么？

292
00:05:45,350 --> 00:05:45,360
我们在这里期待什么？

293
00:05:45,360 --> 00:05:46,950
我们在这里期待什么？

294
00:05:46,950 --> 00:05:46,960
我们在这里期待什么？

295
00:05:46,960 --> 00:05:49,950
我们在这里期待什么？

296
00:05:49,950 --> 00:05:49,960
中层可能做得好的时候

297
00:05:49,960 --> 00:05:52,390
当你或我认识到数字时，我们就能很好地处理这些数字。

298
00:05:52,390 --> 00:05:52,400
你或我认识数字，我们拼凑起来

299
00:05:52,400 --> 00:05:54,830
当你或我识别数字时，我们将各种成分拼凑在一起。

300
00:05:54,830 --> 00:05:54,840
九有一个环

301
00:05:54,840 --> 00:05:57,510
一个九在上面有一个环，在右边有一条线。

302
00:05:57,510 --> 00:05:57,520
上面有一圈，右边有一条线

303
00:05:57,520 --> 00:05:59,670
8 的顶部也有一个环，但它的右侧有一条线，而 9 的顶部也有一个环，但它的左侧有一条线。

304
00:05:59,670 --> 00:05:59,680
8 也有一个环在上面，但它是

305
00:05:59,680 --> 00:06:03,029
8 也有一个环在上面，但它与另一个环在下面配对。

306
00:06:03,029 --> 00:06:03,039
在低处与另一圈配对

307
00:06:03,039 --> 00:06:04,670
基本上可以分成三组

308
00:06:04,670 --> 00:06:04,680
基本分为三个

309
00:06:04,680 --> 00:06:07,710
基本上可以分解成三条特定的线和类似的东西了

310
00:06:07,710 --> 00:06:07,720
现在

311
00:06:07,720 --> 00:06:09,909
在一个完美的世界里，我们可能希望

312
00:06:09,909 --> 00:06:09,919
在一个完美的世界里，我们希望

313
00:06:09,919 --> 00:06:12,550
在一个完美的世界里，我们可能希望倒数第二层的每个神经元

314
00:06:12,550 --> 00:06:12,560
倒数第二层的每个神经元

315
00:06:12,560 --> 00:06:14,270
第二层到最后一层的每个神经元都与其中一个

316
00:06:14,270 --> 00:06:14,280
对应其中一个

317
00:06:14,280 --> 00:06:16,350
对应的子组件之一

318
00:06:16,350 --> 00:06:16,360
随时输入的子组件

319
00:06:16,360 --> 00:06:19,309
只要输入图像，例如顶部有一个像 9 的循环，就会产生一个子组件。

320
00:06:19,309 --> 00:06:19,319
图像顶部有一个类似 9 的循环

321
00:06:19,319 --> 00:06:21,790
如果图像的顶部有一个像 9 或 8 这样的循环，那么就会有一些特定的神经元

322
00:06:21,790 --> 00:06:21,800
或 8 有一些特定的神经元

323
00:06:21,800 --> 00:06:23,430
或 "8 "有一些特定的神经元，其激活将接近于 "9 "或 "8"。

324
00:06:23,430 --> 00:06:23,440
其激活将接近

325
00:06:23,440 --> 00:06:25,950
我指的不是这个特定的环路。

326
00:06:25,950 --> 00:06:25,960
我指的不是这个特定的环路。

327
00:06:25,960 --> 00:06:28,070
我指的不是这个特定的像素环路，而是希望任何一个像素环路都能被激活。

328
00:06:28,070 --> 00:06:28,080
我希望能有更多的像素

329
00:06:28,080 --> 00:06:30,430
我们希望，任何一般的循环模式都能在 WS 的顶端出现。

330
00:06:30,430 --> 00:06:30,440
在这个问题上

331
00:06:30,440 --> 00:06:33,350
一般循环模式到 WS 顶部会触发这个神经元，从

332
00:06:33,350 --> 00:06:33,360
触发这个神经元，从

333
00:06:33,360 --> 00:06:35,550
从第三层到最后一层就这样触发了这个神经元

334
00:06:35,550 --> 00:06:35,560
第三层到最后一层

335
00:06:35,560 --> 00:06:37,710
从第三层到最后一层，只需要学习哪种神经元的组合就可以了。

336
00:06:37,710 --> 00:06:37,720
需要了解哪些子组件的组合

337
00:06:37,720 --> 00:06:39,950
需要了解哪些子组件的组合与哪些

338
00:06:39,950 --> 00:06:39,960
哪个子部件对应哪个

339
00:06:39,960 --> 00:06:42,189
这就需要学习哪些子部件的组合与哪些数字的组合相对应，而哪些数字的组合恰恰会使"......

340
00:06:42,189 --> 00:06:42,199
当然

341
00:06:42,199 --> 00:06:43,830
当然，这只是把问题抛到了九霄云外。

342
00:06:43,830 --> 00:06:43,840
因为

343
00:06:43,840 --> 00:06:45,550
因为你如何识别这些子部件？

344
00:06:45,550 --> 00:06:45,560
或者

345
00:06:45,560 --> 00:06:47,110
因为你如何识别这些子组件，甚至了解什么是正确的子组件？

346
00:06:47,110 --> 00:06:47,120
甚至了解什么是正确的子组件

347
00:06:47,120 --> 00:06:48,670
我甚至还不知道正确的子组件应该是什么，我甚至还不知道正确的子组件应该是什么，我甚至还不知道正确的子组件应该是什么。

348
00:06:48,670 --> 00:06:48,680
我甚至还没有

349
00:06:48,680 --> 00:06:50,430
我甚至还没有谈到一层是如何影响另一层的。

350
00:06:50,430 --> 00:06:50,440
我甚至还没有讨论过一层是如何影响下一层的。

351
00:06:50,440 --> 00:06:52,589
我甚至还没有谈到一层是如何影响下一层的。

352
00:06:52,589 --> 00:06:52,599
但是，请跟我一起讨论这一层对下一层的影响。

353
00:06:52,599 --> 00:06:55,189
但是，请先跟我说说这一层是如何影响下一层的。

354
00:06:55,189 --> 00:06:55,199
在这一时刻，认识到一个循环也可以

355
00:06:55,199 --> 00:06:57,550
我们可以把问题分解成一个个子问题，一个个地解决。

356
00:06:57,550 --> 00:06:57,560
分解成一个个子问题

357
00:06:57,560 --> 00:06:59,150
要做到这一点，一个合理的方法是

358
00:06:59,150 --> 00:06:59,160
合理的做法是

359
00:06:59,160 --> 00:07:01,869
合理的做法是 首先识别各种小边缘

360
00:07:01,869 --> 00:07:01,879
首先要认识到各种小边缘

361
00:07:01,879 --> 00:07:05,309
首先认识到组成类似长线的各种小边

362
00:07:05,309 --> 00:07:05,319
组成一条长线

363
00:07:05,319 --> 00:07:06,469
组成一条长长的线，就像你在

364
00:07:06,469 --> 00:07:06,479
的那种

365
00:07:06,479 --> 00:07:09,070
就像你可能会在数字一、四或七中看到的那种，那就是

366
00:07:09,070 --> 00:07:09,080
数字一、四、七

367
00:07:09,080 --> 00:07:11,189
你可能会在数字一、四或七中看到这种情况。

368
00:07:11,189 --> 00:07:11,199
也许你

369
00:07:11,199 --> 00:07:13,029
或者你把它看成是某种模式的 "边缘"。

370
00:07:13,029 --> 00:07:13,039
把它看成是

371
00:07:13,039 --> 00:07:17,150
把它看成是由几条较小的边缘组成的某种模式，所以也许我们的希望是

372
00:07:17,150 --> 00:07:17,160
也许我们的希望是

373
00:07:17,160 --> 00:07:19,070
因此，我们希望第二层中的每个神经元

374
00:07:19,070 --> 00:07:19,080
是第二层中的每个神经元

375
00:07:19,080 --> 00:07:21,110
是网络第二层的每个神经元都与网络第三层的神经元相对应。

376
00:07:21,110 --> 00:07:21,120
网络中的每个神经元都与

377
00:07:21,120 --> 00:07:24,189
网络中的每一个神经元都与各种相关的小边缘相对应。

378
00:07:24,189 --> 00:07:24,199
当一幅图像中可能存在各种相关的小边缘时

379
00:07:24,199 --> 00:07:26,749
当像这样的图像出现时，可能会出现各种相关的小边缘

380
00:07:26,749 --> 00:07:26,759
像这样的图像出现时

381
00:07:26,759 --> 00:07:29,110
像这样的图像出现时，与之相关的所有神经元都会被点亮

382
00:07:29,110 --> 00:07:29,120
所有相关的神经元

383
00:07:29,120 --> 00:07:31,270
与大约 8 到 10 个特定的小边缘相关的所有神经元

384
00:07:31,270 --> 00:07:31,280
约8到10个特定的小

385
00:07:31,280 --> 00:07:33,510
这反过来又照亮了神经元的边缘。

386
00:07:33,510 --> 00:07:33,520
边缘，进而点亮神经元。

387
00:07:33,520 --> 00:07:35,510
而与上环相关的神经元也会被点亮。

388
00:07:35,510 --> 00:07:35,520
与上环相关的神经元

389
00:07:35,520 --> 00:07:38,029
与上环相关的神经元，以及一条长垂直线和那些光

390
00:07:38,029 --> 00:07:38,039
和一条长垂直线，这些光

391
00:07:38,039 --> 00:07:40,589
和一条长竖线，这些光亮照亮了与九宫格相关的神经元。

392
00:07:40,589 --> 00:07:40,599
与 "9 "相关的神经元

393
00:07:40,599 --> 00:07:41,909
我们的最终结果是什么？

394
00:07:41,909 --> 00:07:41,919
这是否就是我们的最终结果？

395
00:07:41,919 --> 00:07:43,869
网络的实际作用是另一个问题。

396
00:07:43,869 --> 00:07:43,879
网络的实际作用是另一个问题

397
00:07:43,879 --> 00:07:45,749
网络实际上做的是另一个问题，我会回来一次

398
00:07:45,749 --> 00:07:45,759
问题一，我会回来一次

399
00:07:45,759 --> 00:07:47,990
我们看到了如何训练网络，但是这

400
00:07:47,990 --> 00:07:48,000
我们看到了如何训练网络，但这

401
00:07:48,000 --> 00:07:50,270
但这是一个希望，我们可能会有一种......

402
00:07:50,270 --> 00:07:50,280
但这是一个希望，我们可能有一种

403
00:07:50,280 --> 00:07:52,110
在这种情况下，我们有可能通过分层结构实现某种目标。

404
00:07:52,110 --> 00:07:52,120
分层结构的目标

405
00:07:52,120 --> 00:07:54,749
此外，你还可以想象，作为一个人，我们是如何成为一个 "人 "的。

406
00:07:54,749 --> 00:07:54,759
此外，你还可以想象

407
00:07:54,759 --> 00:07:56,749
此外，你还可以想象如何能够检测到边缘和模式，如

408
00:07:56,749 --> 00:07:56,759
检测边缘和模式

409
00:07:56,759 --> 00:07:58,790
能检测到这样的边缘和模式，对其他领域真的很有用。

410
00:07:58,790 --> 00:07:58,800
这对其他

411
00:07:58,800 --> 00:08:01,909
这对于其他图像识别任务，甚至是图像识别以外的任务，都会非常有用。

412
00:08:01,909 --> 00:08:01,919
图像识别任务，甚至超越图像

413
00:08:01,919 --> 00:08:03,390
图像识别任务，甚至是图像识别之外的任务。

414
00:08:03,390 --> 00:08:03,400
除了图像识别，还有各种

415
00:08:03,400 --> 00:08:05,189
在图像识别之外，你可能还想做各种各样的智能事情。

416
00:08:05,189 --> 00:08:05,199
你可能想做的智能事情

417
00:08:05,199 --> 00:08:06,790
在图像识别任务之外，还有各种各样的智能识别任务。

418
00:08:06,790 --> 00:08:06,800
抽象层

419
00:08:06,800 --> 00:08:09,629
例如，对语音进行抽象解析。

420
00:08:09,629 --> 00:08:09,639
例如，抽象解析语音

421
00:08:09,639 --> 00:08:11,510
例如，对语音进行抽象解析时，需要采集原始音频，然后进行筛选。

422
00:08:11,510 --> 00:08:11,520
包括获取原始音频并挑选出

423
00:08:11,520 --> 00:08:13,950
这就需要提取原始音频，并挑选出不同的声音，这些声音结合在一起，形成了一个语音识别系统。

424
00:08:13,950 --> 00:08:13,960
将不同的声音组合在一起

425
00:08:13,960 --> 00:08:16,149
这些声音组合成某些音节，这些音节组合成

426
00:08:16,149 --> 00:08:16,159
这些声音组合成某些音节

427
00:08:16,159 --> 00:08:17,909
这些音节组合成单词，这些单词组合成词语。

428
00:08:17,909 --> 00:08:17,919
组成单词

429
00:08:17,919 --> 00:08:21,149
这些词组合成短语和更抽象的思想等。

430
00:08:21,149 --> 00:08:21,159
詞組和更抽象的思想等

431
00:08:21,159 --> 00:08:22,830
但我们还是要回过头来看这些词是如何构成的。

432
00:08:22,830 --> 00:08:22,840
但还是要回到如何

433
00:08:22,840 --> 00:08:24,830
但是，我们还是要回到这一切的实际运作方式上来。

434
00:08:24,830 --> 00:08:24,840
你现在正在设计你自己的

435
00:08:24,840 --> 00:08:26,909
现在，你正在设计"'......'到底是怎样的？

436
00:08:26,909 --> 00:08:26,919
现在设计

437
00:08:26,919 --> 00:08:28,990
现在，我们要设计的是，某一层的激活究竟是如何决定的？

438
00:08:28,990 --> 00:08:29,000
这一层的激活是如何决定的？

439
00:08:29,000 --> 00:08:31,749
这一层的激活可能会决定下一层的激活。

440
00:08:31,749 --> 00:08:31,759
下一层的激活目标是

441
00:08:31,759 --> 00:08:33,750
我们的目标是建立某种机制，以确定下一层的激活状态。

442
00:08:33,750 --> 00:08:33,760
有某种机制可以

443
00:08:33,760 --> 00:08:36,550
我们的目标是建立某种机制，可以将像素组合成边缘，或将边缘组合成像素。

444
00:08:36,550 --> 00:08:36,560
将像素组合成边缘，或将边缘组合成像素。

445
00:08:36,560 --> 00:08:38,589
我们的目标是建立某种机制，可以设想把像素组合成边，或把边组合成图案，或把图案组合成像素，或把像素组合成边。

446
00:08:38,589 --> 00:08:38,599
将像素组合成边缘

447
00:08:38,599 --> 00:08:40,909
将像素组合成边，或将边组合成图案，或将图案组合成边，或将边组合成图案，或将图案组合成图案，或将图案组合成数字，并将一个非常

448
00:08:40,909 --> 00:08:40,919
将一个非常小的像素点放大到一个非常小的数 字点，将一个非常小的像素点放大到一个非常小的数 字点。

449
00:08:40,919 --> 00:08:43,230
比方说，我们的希望是在一个非常具体的例子中，把一个非常具体的数字放大。

450
00:08:43,230 --> 00:08:43,240
我们的希望是

451
00:08:43,240 --> 00:08:45,710
让我们把希望寄托在第二个神经元中的一个特定神经元上。

452
00:08:45,710 --> 00:08:45,720
第二节中的一个特定神经元

453
00:08:45,720 --> 00:08:47,910
希望第二层中的一个特定神经元能识别出 "阈值 "是否与 "阈值 "相关。

454
00:08:47,910 --> 00:08:47,920
层中的一个特定神经元

455
00:08:47,920 --> 00:08:51,350
图像在此处区域是否有边缘

456
00:08:51,350 --> 00:08:51,360
图像在此处区域有边缘

457
00:08:51,360 --> 00:08:54,030
图像在此区域是否有边缘？

458
00:08:54,030 --> 00:08:54,040
目前的问题是应该使用哪些参数

459
00:08:54,040 --> 00:08:56,630
网络应该有哪些参数？

460
00:08:56,630 --> 00:08:56,640
网络应具备哪些参数？

461
00:08:56,640 --> 00:08:58,750
网络应该有哪些拨盘和旋钮可以调整？

462
00:08:58,750 --> 00:08:58,760
在网络中，有哪些参数是可以调整的？

463
00:08:58,760 --> 00:09:00,470
在网络上有哪些拨号盘和旋钮？

464
00:09:00,470 --> 00:09:00,480
你是否有能力调整这些旋钮？

465
00:09:00,480 --> 00:09:03,110
它足够快，有可能捕捉到这种模式或任何

466
00:09:03,110 --> 00:09:03,120
有可能捕捉到这种图案或任何

467
00:09:03,120 --> 00:09:05,310
有可能捕捉到这种图案或任何其他像素图案或

468
00:09:05,310 --> 00:09:05,320
其他像素图案或

469
00:09:05,320 --> 00:09:07,069
在这种情况下，我们可以通过"......

470
00:09:07,069 --> 00:09:07,079
几条边可以形成一个循环，其他

471
00:09:07,079 --> 00:09:10,069
我们要做的就是将这些图案分配给其他像素。

472
00:09:10,069 --> 00:09:10,079
我们要做的就是分配

473
00:09:10,079 --> 00:09:12,550
我们要做的就是给每条连接线分配一个权重

474
00:09:12,550 --> 00:09:12,560
为每个连接赋予权重

475
00:09:12,560 --> 00:09:14,790
在我们的神经元和其他神经元之间的连接上分配一个权重。

476
00:09:14,790 --> 00:09:14,800
我们的神经元与来自

477
00:09:14,800 --> 00:09:17,630
我们的神经元和第一层的神经元之间的每一个连接都分配一个权重。

478
00:09:17,630 --> 00:09:17,640
这些权重只是

479
00:09:17,640 --> 00:09:20,190
这些权重只是第一层的数字。

480
00:09:20,190 --> 00:09:20,200
然后将所有这些

481
00:09:20,200 --> 00:09:22,590
然后从第一层和第二层的神经元中提取所有的激活值，再从第一层和第二层的神经元中提取所有的激活值。

482
00:09:22,590 --> 00:09:22,600
然后将第一层的所有激活值

483
00:09:22,600 --> 00:09:24,870
计算它们的加权和。

484
00:09:24,870 --> 00:09:24,880
计算它们的加权和

485
00:09:24,880 --> 00:09:26,550
计算它们的加权和

486
00:09:26,550 --> 00:09:26,560
加权和

487
00:09:26,560 --> 00:09:28,670
这些权重

488
00:09:28,670 --> 00:09:28,680
权重

489
00:09:28,680 --> 00:09:30,030
我觉得把这些权重组织起来很有帮助

490
00:09:30,030 --> 00:09:30,040
将这些权重组织起来

491
00:09:30,040 --> 00:09:32,630
这些砝码被组织成一个自己的小网格，而我

492
00:09:32,630 --> 00:09:32,640
成一个自己的小网格，我

493
00:09:32,640 --> 00:09:34,310
我将用绿色像素来表示

494
00:09:34,310 --> 00:09:34,320
用绿色像素表示

495
00:09:34,320 --> 00:09:36,069
用绿色像素表示正权重，用红色像素表示正权重，用红色像素表示负权重。

496
00:09:36,069 --> 00:09:36,079
正权重，红色像素表示

497
00:09:36,079 --> 00:09:37,829
正权重，红色像素表示负权重。

498
00:09:37,829 --> 00:09:37,839
表示负权重。

499
00:09:37,839 --> 00:09:40,230
红色像素表示负权重。

500
00:09:40,230 --> 00:09:40,240
该像素的亮度会受到一定程度的影响。

501
00:09:40,240 --> 00:09:43,030
现在，如果我们对权重值进行描述，就会发现该像素的亮度与权重值的描述有些松散。

502
00:09:43,030 --> 00:09:43,040
权重值的描述

503
00:09:43,040 --> 00:09:44,750
现在，如果我们将权重值与几乎所有像素的亮度相关联，那么权重值的描述就会变得非常简单。

504
00:09:44,750 --> 00:09:44,760
使权重几乎与所有像素相关。

505
00:09:44,760 --> 00:09:47,030
除了部分像素外，几乎所有像素的权重都为零。

506
00:09:47,030 --> 00:09:47,040
除部分像素外，所有像素均为零

507
00:09:47,040 --> 00:09:48,829
在这一区域，除了一些正权重外，所有像素的权重都为零。

508
00:09:48,829 --> 00:09:48,839
该区域的正权重

509
00:09:48,839 --> 00:09:51,470
然后求出加权和。

510
00:09:51,470 --> 00:09:51,480
然后求加权和

511
00:09:51,480 --> 00:09:53,470
然后取所有像素值的加权和，其实只是

512
00:09:53,470 --> 00:09:53,480
所有像素值的加权和

513
00:09:53,480 --> 00:09:55,230
相当于将所有像素值相加。

514
00:09:55,230 --> 00:09:55,240
等于将各像素值相加

515
00:09:55,240 --> 00:09:57,949
将我们所关注的区域内的像素值相加。

516
00:09:57,949 --> 00:09:57,959
我们所关注区域内的像素

517
00:09:57,959 --> 00:10:00,030
如果你真的想这样做的话

518
00:10:00,030 --> 00:10:00,040
如果你真的想

519
00:10:00,040 --> 00:10:02,590
如果你真的想了解这里是否有一个边缘

520
00:10:02,590 --> 00:10:02,600
你可能会做的是

521
00:10:02,600 --> 00:10:04,190
你可能会做的是有一些负面影响。

522
00:10:04,190 --> 00:10:04,200
你可能会做的是

523
00:10:04,200 --> 00:10:06,470
你可能会做的是，与周围环境相关的负权重。

524
00:10:06,470 --> 00:10:06,480
与周围像素相关的权重

525
00:10:06,480 --> 00:10:09,310
当周围像素的权重为负数时，总和最大；当周围像素的权重为正数时，总和最小。

526
00:10:09,310 --> 00:10:09,320
像素时，总和最大。

527
00:10:09,320 --> 00:10:10,990
当中间的像素变亮但周围的像素变暗时，总和最大。

528
00:10:10,990 --> 00:10:11,000
中间像素明亮，但周围像素

529
00:10:11,000 --> 00:10:13,590
中间像素明亮，但周围像素明亮。

530
00:10:13,590 --> 00:10:13,600
周围像素

531
00:10:13,600 --> 00:10:15,910
计算加权总和时，周围像素较暗

532
00:10:15,910 --> 00:10:15,920
计算加权和时颜色较暗

533
00:10:15,920 --> 00:10:17,829
这样计算加权和时，你可能会得出任何结果。

534
00:10:17,829 --> 00:10:17,839
像这样

535
00:10:17,839 --> 00:10:20,190
但对于这个网络，我们想要的是

536
00:10:20,190 --> 00:10:20,200
但对于这个网络，我们想要的是

537
00:10:20,200 --> 00:10:22,150
但对这个网络来说，我们想要的是激活值是某个值

538
00:10:22,150 --> 00:10:22,160
激活值是某个值

539
00:10:22,160 --> 00:10:24,829
我们希望激活值介于 0o 和 1 之间。

540
00:10:24,829 --> 00:10:24,839
0和1之间的某个值，因此

541
00:10:24,839 --> 00:10:27,389
因此，常见的做法是将这个加权和输入到"...... "中。

542
00:10:27,389 --> 00:10:27,399
将这个加权和注入

543
00:10:27,399 --> 00:10:29,069
就是把这个加权和注入某个函数，这个函数会压扁实数。

544
00:10:29,069 --> 00:10:29,079
某个压扁实数的函数

545
00:10:29,079 --> 00:10:30,710
将实数数列挤入数域的函数

546
00:10:30,710 --> 00:10:30,720
将实数数列挤入范围的函数

547
00:10:30,720 --> 00:10:33,230
将实数数列挤入介于 0 和 1 之间的范围的数列和一个普通函数

548
00:10:33,230 --> 00:10:33,240
介于 0 和 1 之间的普通函数

549
00:10:33,240 --> 00:10:35,030
在 0 和 1 之间的一个普通函数叫做 sigmoid

550
00:10:35,030 --> 00:10:35,040
这样做的函数叫做 sigmoid

551
00:10:35,040 --> 00:10:38,030
的函数称为 sigmoid 函数，也称为 logistic 曲线

552
00:10:38,030 --> 00:10:38,040
也称为对数曲线的函数

553
00:10:38,040 --> 00:10:40,150
基本上，非常负的输入最终会导致非常负的输出。

554
00:10:40,150 --> 00:10:40,160
基本上，非常负的输入最终会

555
00:10:40,160 --> 00:10:42,550
基本上，非常负的输入最终会接近零 非常正的输入最终会接近零

556
00:10:42,550 --> 00:10:42,560
非常正的输入接近零时结束

557
00:10:42,560 --> 00:10:44,750
非常正的输入最终接近于零 非常正的输入最终接近于一，并且稳定地

558
00:10:44,750 --> 00:10:44,760
接近于零

559
00:10:44,760 --> 00:10:48,350
在输入零点附近稳步上升。

560
00:10:48,360 --> 00:10:51,150
零，因此神经元的活化

561
00:10:51,150 --> 00:10:51,160
因此，神经元的激活率为零。

562
00:10:51,160 --> 00:10:53,910
因此，神经元的活化基本上是衡量神经元在输入量为零时的活化程度。

563
00:10:53,910 --> 00:10:53,920
这里基本上是衡量

564
00:10:53,920 --> 00:10:56,829
这里基本上是衡量相关加权和的正向程度。

565
00:10:56,829 --> 00:10:56,839
正相关加权和

566
00:10:56,839 --> 00:10:59,389
但也许这并不是你想要的结果。

567
00:10:59,389 --> 00:10:59,399
但也许这并不是你想要的结果。

568
00:10:59,399 --> 00:11:00,990
但也许你并不希望神经元在加权和为正时亮灯。

569
00:11:00,990 --> 00:11:01,000
加权和时神经元亮起

570
00:11:01,000 --> 00:11:03,230
当加权和大于零时，神经元就会亮起来。

571
00:11:03,230 --> 00:11:03,240
大于零，也许你只想要

572
00:11:03,240 --> 00:11:05,190
也许你只想让它在总和大于零时才起作用。

573
00:11:05,190 --> 00:11:05,200
当总和大于 0 时启动

574
00:11:05,200 --> 00:11:08,910
当总和大于 10 时，它才会激活，也就是说，你需要一些偏差

575
00:11:08,910 --> 00:11:08,920
比 10 大，你需要一些偏差

576
00:11:08,920 --> 00:11:10,190
比 10 大时，你需要一些偏差。

577
00:11:10,190 --> 00:11:10,200
让它

578
00:11:10,200 --> 00:11:12,710
那么我们要做的就是加上

579
00:11:12,710 --> 00:11:12,720
那么我们要做的就是加入

580
00:11:12,720 --> 00:11:15,550
我们要做的就是在此基础上添加一些其他数字，比如-10

581
00:11:15,550 --> 00:11:15,560
在此基础上加上-10

582
00:11:15,560 --> 00:11:17,829
在将其插入加权总和之前，先将其他一些数字（如-10）加到这个加权总和中。

583
00:11:17,829 --> 00:11:17,839
插入前的加权和

584
00:11:17,839 --> 00:11:20,590
将加权和插入 sigmoid 平方修正函数之前

585
00:11:20,590 --> 00:11:20,600
σ斜方函数

586
00:11:20,600 --> 00:11:22,430
该附加数字称为

587
00:11:22,430 --> 00:11:22,440
这个额外的数字叫做

588
00:11:22,440 --> 00:11:25,629
因此，权重会告诉你哪个像素的偏差最大，哪个像素的偏差最小。

589
00:11:25,629 --> 00:11:25,639
因此，权重会告诉你哪个像素的偏差是多少。

590
00:11:25,639 --> 00:11:27,310
所以权重会告诉你第二层神经元的像素模式是什么。

591
00:11:27,310 --> 00:11:27,320
第二层中这个神经元的模式

592
00:11:27,320 --> 00:11:30,230
因此，权重会告诉你第二层的这个神经元捕捉到了什么像素模式。

593
00:11:30,230 --> 00:11:30,240
偏置告诉你

594
00:11:30,240 --> 00:11:32,550
偏差会告诉你加权总和需要多高。

595
00:11:32,550 --> 00:11:32,560
加权和需要多高

596
00:11:32,560 --> 00:11:33,990
在神经元开始对其进行分析之前，加权和需要达到多高的水平？

597
00:11:33,990 --> 00:11:34,000
在神经元开始获得

598
00:11:34,000 --> 00:11:37,310
在神经元开始有意义地活跃之前，这只是一个

599
00:11:37,310 --> 00:11:37,320
神经元开始有意义地活跃，这只是一个

600
00:11:37,320 --> 00:11:40,629
在神经元开始有意义地活跃之前，这只是一个神经元

601
00:11:40,629 --> 00:11:40,639
这一层中的每一个神经元

602
00:11:40,639 --> 00:11:43,230
这一层中的每一个神经元都将与所有 784 个神经元相连。

603
00:11:43,230 --> 00:11:43,240
将与所有 784 个神经元相连

604
00:11:43,240 --> 00:11:45,710
连接到第一层的所有 784 个像素神经元和第二层的所有 784 个像素神经元。

605
00:11:45,710 --> 00:11:45,720
来自第一层的像素神经元和来自第二层的每个像素神经元。

606
00:11:45,720 --> 00:11:48,710
第一层的像素神经元和第二层的像素神经元，而这 784 个连接中的每一个都有

607
00:11:48,710 --> 00:11:48,720
这 784 个连接中的每一个都有

608
00:11:48,720 --> 00:11:51,990
这 784 个连接中的每一个连接都有自己的权重。

609
00:11:51,990 --> 00:11:52,000
也有自己的权重

610
00:11:52,000 --> 00:11:54,350
每个连接都有一定的偏差，比如其他数字

611
00:11:54,350 --> 00:11:54,360
每个连接都有一定的偏差

612
00:11:54,360 --> 00:11:55,949
每个连接都有一些偏差，而这些偏差会被加到加权总和中。

613
00:11:55,949 --> 00:11:55,959
加到加权和上

614
00:11:55,959 --> 00:11:58,389
在用 sigmoid 对加权和进行挤压之前，在加权和上添加的数字。

615
00:11:58,389 --> 00:11:58,399
和

616
00:11:58,399 --> 00:12:00,150
这需要考虑很多问题。

617
00:12:00,150 --> 00:12:00,160
要考虑的事情太多了

618
00:12:00,160 --> 00:12:02,670
这个由 16 个神经元组成的隐藏层是一个

619
00:12:02,670 --> 00:12:02,680
这个由 16 个神经元组成的隐藏层是一个

620
00:12:02,680 --> 00:12:07,750
这个由 16 个神经元组成的隐藏层共有 784 * 16 个权重，其中包括 16 个神经元的权重。

621
00:12:07,750 --> 00:12:07,760
共 784 * 16 个权重，以及 16 个神经元。

622
00:12:07,760 --> 00:12:10,030
16 个权重以及 16 个偏置。

623
00:12:10,030 --> 00:12:10,040
所有这些都只是

624
00:12:10,040 --> 00:12:11,629
所有这些都只是从第一层到第二层的连接。

625
00:12:11,629 --> 00:12:11,639
从第一层到第二层的连接

626
00:12:11,639 --> 00:12:13,790
从第一层到第二层的连接

627
00:12:13,790 --> 00:12:13,800
第二层之间的连接

628
00:12:13,800 --> 00:12:15,790
其他层之间的连接也有一堆权重和偏差。

629
00:12:15,790 --> 00:12:15,800
层之间的连接也有一堆权重和

630
00:12:15,800 --> 00:12:18,829
这些层之间的连接也有一堆权重和偏差。

631
00:12:18,829 --> 00:12:18,839
与它们相关的偏差

632
00:12:18,839 --> 00:12:21,470
这个网络几乎完全一样

633
00:12:21,470 --> 00:12:21,480
这个网络几乎完全

634
00:12:21,480 --> 00:12:25,230
这个网络几乎完全拥有 13,000 个权重和偏差。

635
00:12:25,230 --> 00:12:25,240
13,000 个总权重和偏差

636
00:12:25,240 --> 00:12:27,189
13,000个可调整的旋钮和刻度盘，以及

637
00:12:27,189 --> 00:12:27,199
可调旋钮和刻度盘

638
00:12:27,199 --> 00:12:29,230
可以调整和旋转的旋钮和刻度盘，使这个网络的行为和偏差达到最佳状态。

639
00:12:29,230 --> 00:12:29,240
这些旋钮和拨盘可以进行调整和旋转，使这个网络的行为

640
00:12:29,240 --> 00:12:31,910
因此，当我们谈论 "网络 "这个词时，就会发现它有不同的含义。

641
00:12:31,910 --> 00:12:31,920
因此，当我们谈论学习时

642
00:12:31,920 --> 00:12:34,430
因此，当我们谈论学习时，我们指的是

643
00:12:34,430 --> 00:12:34,440
学习

644
00:12:34,440 --> 00:12:36,590
当我们谈论学习时，指的是让计算机找到一个有效的

645
00:12:36,590 --> 00:12:36,600
让计算机找到有效的设置

646
00:12:36,600 --> 00:12:38,430
让计算机为所有这些许许多多的设置找到一个有效的设置

647
00:12:38,430 --> 00:12:38,440
这些设置

648
00:12:38,440 --> 00:12:40,430
为所有这些许多许多的数字设置，这样它就能真正解出

649
00:12:40,430 --> 00:12:40,440
数字

650
00:12:40,440 --> 00:12:41,470
这样，它就能真正解决

651
00:12:41,470 --> 00:12:41,480
问题

652
00:12:41,480 --> 00:12:44,150
我们正在进行的一个思想实验

653
00:12:44,150 --> 00:12:44,160
我们要做的是

654
00:12:44,160 --> 00:12:46,509
这个思想实验既有趣又令人毛骨悚然。

655
00:12:46,509 --> 00:12:46,519
这是个既有趣又可怕的思想实验

656
00:12:46,519 --> 00:12:48,350
一个既有趣又可怕的思想实验是，想象一下坐下来，把所有的

657
00:12:48,350 --> 00:12:48,360
想象一下，坐下来设置所有这些

658
00:12:48,360 --> 00:12:50,310
想象一下，坐下来手工设置所有这些权重和偏差

659
00:12:50,310 --> 00:12:50,320
手工设置这些权重和偏差

660
00:12:50,320 --> 00:12:52,030
有目的地调整数字，以便

661
00:12:52,030 --> 00:12:52,040
有目的地调整数字

662
00:12:52,040 --> 00:12:54,269
有目的地调整这些数字，以便第二层能捕捉到边缘的信息

663
00:12:54,269 --> 00:12:54,279
第二层拾取的是边缘部分

664
00:12:54,279 --> 00:12:57,269
第㆓層揀選邊緣，第㆔層揀選模式等。

665
00:12:57,269 --> 00:12:57,279
第三层拾取图案等

666
00:12:57,279 --> 00:12:59,189
我个人认为这样做比较令人满意。

667
00:12:59,189 --> 00:12:59,199
我个人认为这样做比较令人满意

668
00:12:59,199 --> 00:13:00,430
我个人认为，这比仅仅把网络当作网络来处理更令人满意。

669
00:13:00,430 --> 00:13:00,440
而不是仅仅把网络当作

670
00:13:00,440 --> 00:13:02,790
而不是仅仅把网络当作一个完全的黑盒子，因为当

671
00:13:02,790 --> 00:13:02,800
因为当网络是一个完全的黑盒子时

672
00:13:02,800 --> 00:13:04,550
因为当网络的性能不符合你的要求时，你就会发现它是一个完全的黑盒子。

673
00:13:04,550 --> 00:13:04,560
因为当网络的性能不符合您的要求时

674
00:13:04,560 --> 00:13:06,590
因为当网络的性能不符合你的预期时，如果你已经建立了一个小的

675
00:13:06,590 --> 00:13:06,600
如果你已经建立了一点

676
00:13:06,600 --> 00:13:08,110
如果你已经与这些人建立了一点关系

677
00:13:08,110 --> 00:13:08,120
与这些

678
00:13:08,120 --> 00:13:10,350
这些权重和偏差实际上意味着什么？

679
00:13:10,350 --> 00:13:10,360
权重和偏差实际上意味着你

680
00:13:10,360 --> 00:13:12,150
权重和偏差实际上意味着你有了实验的起点

681
00:13:12,150 --> 00:13:12,160
实验的起点

682
00:13:12,160 --> 00:13:13,870
有了实验的起点，就可以研究如何改变结构，以便

683
00:13:13,870 --> 00:13:13,880
如何改变结构

684
00:13:13,880 --> 00:13:16,430
如何改变结构，以改进网络或当网络工作时

685
00:13:16,430 --> 00:13:16,440
改进网络，或当网络发挥作用时

686
00:13:16,440 --> 00:13:18,389
改进网络或当网络发挥作用时，但不是出于你所期望的原因

687
00:13:18,389 --> 00:13:18,399
但不是你所期望的原因

688
00:13:18,399 --> 00:13:20,269
挖掘权重和偏差的原因

689
00:13:20,269 --> 00:13:20,279
挖掘权重和偏差的原因

690
00:13:20,279 --> 00:13:22,110
挖掘权重和偏差在做什么，是一种很好的挑战方式。

691
00:13:22,110 --> 00:13:22,120
我们在做什么？

692
00:13:22,120 --> 00:13:24,030
这是对你的假设提出质疑的好方法，并能真正揭露你的假设和偏差。

693
00:13:24,030 --> 00:13:24,040
你的假设

694
00:13:24,040 --> 00:13:25,710
你的假设，并真正揭示可能的全部空间

695
00:13:25,710 --> 00:13:25,720
在这种情况下

696
00:13:25,720 --> 00:13:28,350
通过实际函数的方式来找到可能的解决方案。

697
00:13:28,350 --> 00:13:28,360
通过实际函数

698
00:13:28,360 --> 00:13:29,829
这里的实际函数写起来有点麻烦。

699
00:13:29,829 --> 00:13:29,839
这里写起来有点麻烦

700
00:13:29,839 --> 00:13:31,710
这里写起来有点麻烦，你不觉得吗？

701
00:13:31,710 --> 00:13:31,720
你不觉得吗？

702
00:13:31,720 --> 00:13:34,110
你不觉得吗？

703
00:13:34,110 --> 00:13:34,120
所以，让我向你们展示一种更

704
00:13:34,120 --> 00:13:35,949
因此，让我向你们展示一种更紧凑的方法，使这些

705
00:13:35,949 --> 00:13:35,959
让我来向你们展示

706
00:13:35,959 --> 00:13:37,990
让我向你们展示一种更加合理紧凑的方式，来表示这些连接。

707
00:13:37,990 --> 00:13:38,000
连接的表示方法

708
00:13:38,000 --> 00:13:39,310
如果你选择向上阅读，你就会看到它。

709
00:13:39,310 --> 00:13:39,320
如果你选择向上阅读

710
00:13:39,320 --> 00:13:41,949
更多有关神经网络的信息，请点击这里。

711
00:13:41,949 --> 00:13:41,959
更多关于神经网络的信息

712
00:13:41,959 --> 00:13:44,670
更多关于神经网络的内容

713
00:13:44,670 --> 00:13:44,680
将一个层的所有激活点

714
00:13:44,680 --> 00:13:46,829
将一层的所有激活值整理为一列

715
00:13:46,829 --> 00:13:46,839
列作为向量

716
00:13:46,839 --> 00:13:49,509
列作为向量，然后组织所有权重

717
00:13:49,509 --> 00:13:49,519
矢量，然后将所有权重整理为

718
00:13:49,519 --> 00:13:52,150
然后将所有权重整理成一个矩阵，矩阵中的每一行都有一个权重。

719
00:13:52,150 --> 00:13:52,160
矩阵

720
00:13:52,160 --> 00:13:54,150
矩阵的每一行都与连接相对应。

721
00:13:54,150 --> 00:13:54,160
矩阵与连接相对应

722
00:13:54,160 --> 00:13:56,389
矩阵对应于一个层与特定层之间的连接

723
00:13:56,389 --> 00:13:56,399
神经元之间的连接

724
00:13:56,399 --> 00:13:59,110
这意味着什么？

725
00:13:59,110 --> 00:13:59,120
下一层的神经元 这意味着什么

726
00:13:59,120 --> 00:14:01,230
下一层神经元的加权总和。

727
00:14:01,230 --> 00:14:01,240
的加权和

728
00:14:01,240 --> 00:14:03,030
就是根据第一层神经元激活的加权和来计算下一层神经元激活的加权和。

729
00:14:03,030 --> 00:14:03,040
第一层激活的加权和

730
00:14:03,040 --> 00:14:05,069
根据这些权重，第一层中的激活值对应于"...... "中的一个。

731
00:14:05,069 --> 00:14:05,079
这些权重对应于

732
00:14:05,079 --> 00:14:07,550
这些权重对应于矩阵矢量乘积中的一个项

733
00:14:07,550 --> 00:14:07,560
矩阵矢量积中的项

734
00:14:07,560 --> 00:14:12,910
左边所有内容的矩阵矢量乘积中的术语

735
00:14:12,920 --> 00:14:15,389
顺便说一下，这里有很多机器

736
00:14:15,389 --> 00:14:15,399
这里的机器

737
00:14:15,399 --> 00:14:16,870
顺便说一下，机器学习的很多方面都可以归结为有一个

738
00:14:16,870 --> 00:14:16,880
机器学习

739
00:14:16,880 --> 00:14:19,150
学习的关键在于熟练掌握线性代数。

740
00:14:19,150 --> 00:14:19,160
掌握线性代数

741
00:14:19,160 --> 00:14:20,829
掌握线性代数，所以对于任何想要一个直观的

742
00:14:20,829 --> 00:14:20,839
想要直观了解线性代数的人

743
00:14:20,839 --> 00:14:22,310
想直观了解矩阵和什么的人来说

744
00:14:22,310 --> 00:14:22,320
了解矩阵和什么

745
00:14:22,320 --> 00:14:24,509
矩阵矢量乘法意味着什么？

746
00:14:24,509 --> 00:14:24,519
矩阵矢量乘法的含义

747
00:14:24,519 --> 00:14:26,470
矩阵矢量乘法意味着什么？

748
00:14:26,470 --> 00:14:26,480
看看我做的线性系列

749
00:14:26,480 --> 00:14:29,629
看看我做的线性代数系列，尤其是第 3 章，回到我们的

750
00:14:29,629 --> 00:14:29,639
代数，尤其是第三章，回到我们的表达式

751
00:14:29,639 --> 00:14:31,389
代数，特别是第三章，回到我们的表达式，而不是谈论

752
00:14:31,389 --> 00:14:31,399
表达式

753
00:14:31,399 --> 00:14:33,189
而不是讨论在每一个表达式中添加偏置

754
00:14:33,189 --> 00:14:33,199
在每个表达式中加入偏置

755
00:14:33,199 --> 00:14:35,910
在每一个独立的值中加入偏置，我们用"...... "来表示。

756
00:14:35,910 --> 00:14:35,920
我们用

757
00:14:35,920 --> 00:14:38,030
我们通过将所有这些偏差组织成一个

758
00:14:38,030 --> 00:14:38,040
将所有这些偏差整理成一个

759
00:14:38,040 --> 00:14:40,430
将所有这些偏差整理成一个矢量，并将整个矢量加到

760
00:14:40,430 --> 00:14:40,440
矢量，并将整个矢量与

761
00:14:40,440 --> 00:14:43,509
然后将整个矢量与前一个矩阵矢量乘积相加。

762
00:14:43,509 --> 00:14:43,519
然后将整个矢量与上一个矩阵矢量乘积相加

763
00:14:43,519 --> 00:14:45,990
作为最后一步，我将用一个 sigmoid

764
00:14:45,990 --> 00:14:46,000
作为最后一步，我将包装一个 sigmoid

765
00:14:46,000 --> 00:14:48,509
作为最后一步，我将在这里的外侧包一个西格米梯形，然后在这里的外侧包一个西格米梯形，然后在这里的外侧包一个西格米梯形。

766
00:14:48,509 --> 00:14:48,519
在这里

767
00:14:48,519 --> 00:14:49,910
这应该代表什么？

768
00:14:49,910 --> 00:14:49,920
你应该代表的是

769
00:14:49,920 --> 00:14:51,550
你应该表示的是，你将把 sigmoid 函数应用于

770
00:14:51,550 --> 00:14:51,560
应用 sigmoid 函数

771
00:14:51,560 --> 00:14:53,870
对结果中的每个特定成分应用 sigmoid 函数。

772
00:14:53,870 --> 00:14:53,880
的每个特定分量

773
00:14:53,880 --> 00:14:54,870
的每个特定分量

774
00:14:54,870 --> 00:14:54,880
矢量

775
00:14:54,880 --> 00:14:57,470
内的矢量，所以一旦你写下这个

776
00:14:57,470 --> 00:14:57,480
内，一旦你写下这个

777
00:14:57,480 --> 00:14:59,430
那么，一旦你把这个权重矩阵和这些向量写成它们的

778
00:14:59,430 --> 00:14:59,440
权重矩阵和这些向量作为它们的

779
00:14:59,440 --> 00:15:02,030
这些向量作为它们自己的符号，你就可以把它们的符号完整地表达出来。

780
00:15:02,030 --> 00:15:02,040
你就可以把所有的转换符号

781
00:15:02,040 --> 00:15:04,150
你就可以完整地表达一层的激活度转换了。

782
00:15:04,150 --> 00:15:04,160
从一层到另一层的激活过渡

783
00:15:04,160 --> 00:15:06,389
在一个极其严密的、由一层到下一层的激活度转换过程中，我们可以将所有的激活度转换信息传递出去。

784
00:15:06,389 --> 00:15:06,399
在一个极其紧凑和

785
00:15:06,399 --> 00:15:08,710
这让人联想到"......"。

786
00:15:08,710 --> 00:15:08,720
整洁的小表达式

787
00:15:08,720 --> 00:15:11,269
这样，相关的代码就会简单得多。

788
00:15:11,269 --> 00:15:11,279
这样，相关的代码就变得简单多了。

789
00:15:11,279 --> 00:15:13,509
这样，相关的代码就简单多了，速度也快多了，因为许多库

790
00:15:13,509 --> 00:15:13,519
由于许多库

791
00:15:13,519 --> 00:15:16,710
由于许多库都对矩阵进行了优化，因此速度快了很多

792
00:15:16,710 --> 00:15:16,720
优化矩阵

793
00:15:16,720 --> 00:15:18,790
优化矩阵乘法 还记得我以前是如何优化矩阵乘法的吗？

794
00:15:18,790 --> 00:15:18,800
乘法运算

795
00:15:18,800 --> 00:15:20,590
还记得早些时候我是怎么说的吗

796
00:15:20,590 --> 00:15:20,600
说这些神经元是简单的东西

797
00:15:20,600 --> 00:15:23,230
这些神经元是简单的东西，当然，它们能很好地保存数字

798
00:15:23,230 --> 00:15:23,240
当然

799
00:15:23,240 --> 00:15:25,150
当然，它们持有的具体数字取决于

800
00:15:25,150 --> 00:15:25,160
它们掌握的具体数字取决于

801
00:15:25,160 --> 00:15:27,189
它们掌握的具体数字取决于你输入的图像

802
00:15:27,189 --> 00:15:27,199
你输入的图像

803
00:15:27,199 --> 00:15:29,710
因此，它实际上是更准确的

804
00:15:29,710 --> 00:15:29,720
因此，它实际上更准确

805
00:15:29,720 --> 00:15:32,150
所以把每个神经元看作一个函数更准确

806
00:15:32,150 --> 00:15:32,160
把每个神经元都看成是一个函数

807
00:15:32,160 --> 00:15:34,470
把每个神经元都看成是一个接收所有神经元输出的函数

808
00:15:34,470 --> 00:15:34,480
一个接收所有神经元输出的函数

809
00:15:34,480 --> 00:15:36,629
将上一层所有神经元的输出接收进来，然后吐出

810
00:15:36,629 --> 00:15:36,639
神经元的输出，然后吐出

811
00:15:36,639 --> 00:15:39,509
神经元，并吐出一个介于 0 和 1 之间的数字。

812
00:15:39,509 --> 00:15:39,519
输出一个介于 0 和 1 之间的数字

813
00:15:39,519 --> 00:15:41,550
整个网络只是一个函数

814
00:15:41,550 --> 00:15:41,560
整个网络只是一个函数

815
00:15:41,560 --> 00:15:44,110
整个网络只是一个函数，一个以 784 个数字为单位的函数，一个以 784 个数字为单位的函数，一个以
784 个数字为单位的函数。

816
00:15:44,110 --> 00:15:44,120
一个把 784 个数字当作一个

817
00:15:44,120 --> 00:15:46,829
它输入 784 个数字，然后输出 10 个数字。

818
00:15:46,829 --> 00:15:46,839
输出 10 个数字作为

819
00:15:46,839 --> 00:15:49,189
输出结果复杂得令人发指。

820
00:15:49,189 --> 00:15:49,199
输出复杂得荒谬

821
00:15:49,199 --> 00:15:51,430
输出是一个荒谬而复杂的函数，其中涉及 13,000 个数字。

822
00:15:51,430 --> 00:15:51,440
一个涉及 13 000 个参数的函数

823
00:15:51,440 --> 00:15:53,110
一个涉及 13,000 个权重形式参数的函数

824
00:15:53,110 --> 00:15:53,120
这些权重形式的参数

825
00:15:53,120 --> 00:15:54,829
这些权重形式的参数和偏差，可以捕捉到某些

826
00:15:54,829 --> 00:15:54,839
和偏差

827
00:15:54,839 --> 00:15:56,710
这些权重和偏差可以捕捉到某些模式和偏差，其中涉及到迭代

828
00:15:56,710 --> 00:15:56,720
模式，这涉及到反复

829
00:15:56,720 --> 00:15:58,509
这就需要迭代许多矩阵矢量乘积和迭代许多矩阵矢量乘积和迭代许多矩阵矢量乘积。

830
00:15:58,509 --> 00:15:58,519
许多矩阵矢量乘积和

831
00:15:58,519 --> 00:16:01,389
它包括迭代许多矩阵矢量乘积和许多矩阵矢量乘积，以及西格玛压扁识别函数，但它是

832
00:16:01,389 --> 00:16:01,399
但它是

833
00:16:01,399 --> 00:16:04,470
尽管如此，它只是一个函数，而且在某种程度上

834
00:16:04,470 --> 00:16:04,480
尽管如此，从某种意义上说，它只是一个函数

835
00:16:04,480 --> 00:16:06,230
在某种程度上，它看起来让人放心

836
00:16:06,230 --> 00:16:06,240
让人放心的是，它看起来

837
00:16:06,240 --> 00:16:08,110
它看起来很复杂，这让人放心，我的意思是，如果它是任何

838
00:16:08,110 --> 00:16:08,120
复杂的话

839
00:16:08,120 --> 00:16:10,069
我的意思是，如果它再简单一点 我们还能有什么希望

840
00:16:10,069 --> 00:16:10,079
我们还有什么希望

841
00:16:10,079 --> 00:16:11,189
我们还有什么希望它能接受我们的挑战？

842
00:16:11,189 --> 00:16:11,199
能接受挑战

843
00:16:11,199 --> 00:16:13,949
能接受识别数字的挑战？

844
00:16:13,949 --> 00:16:13,959
识别数字和如何识别数字

845
00:16:13,959 --> 00:16:16,110
这个网络如何应对这一挑战？

846
00:16:16,110 --> 00:16:16,120
该网络如何

847
00:16:16,120 --> 00:16:18,230
该网络如何学习适当的权重和偏差？

848
00:16:18,230 --> 00:16:18,240
学习适当的权重和偏差

849
00:16:18,240 --> 00:16:20,670
通过观察数据来学习适当的权重和偏差

850
00:16:20,670 --> 00:16:20,680
仅仅通过观察数据

851
00:16:20,680 --> 00:16:22,389
这就是我将在下一个视频中展示的内容。

852
00:16:22,389 --> 00:16:22,399
我将在下一个视频中展示。

853
00:16:22,399 --> 00:16:24,110
在下一个视频中，我还会更深入地探讨这一点

854
00:16:24,110 --> 00:16:24,120
我还将进一步挖掘

855
00:16:24,120 --> 00:16:25,509
我们看到的这个特殊网络是什么？

856
00:16:25,509 --> 00:16:25,519
我们看到的特定网络

857
00:16:25,519 --> 00:16:26,470
我们看到的这个特殊网络

858
00:16:26,470 --> 00:16:26,480
真的

859
00:16:26,480 --> 00:16:28,550
我想我现在要做的

860
00:16:28,550 --> 00:16:28,560
我想我应该说

861
00:16:28,560 --> 00:16:29,910
我想我应该说，订阅留下来

862
00:16:29,910 --> 00:16:29,920
应该说，应该说，应该说，订阅留

863
00:16:29,920 --> 00:16:31,749
我想，我应该说，订阅以便在该视频或任何

864
00:16:31,749 --> 00:16:31,759
视频或任何

865
00:16:31,759 --> 00:16:34,110
通知了该视频或任何新视频的发布时间，但实际上

866
00:16:34,110 --> 00:16:34,120
新视频发布，但实际上

867
00:16:34,120 --> 00:16:35,629
但实际上，你们中的大多数人都不会收到通知。

868
00:16:35,629 --> 00:16:35,639
你们中的大多数人

869
00:16:35,639 --> 00:16:38,189
你们中的大多数人实际上没有收到来自YouTube的通知。

870
00:16:38,189 --> 00:16:38,199
从YouTube的通知，你也许

871
00:16:38,199 --> 00:16:40,110
从YouTube的通知 你也许更诚实 我应该说订阅，所以

872
00:16:40,110 --> 00:16:40,120
更诚实地说，我应该说，所以订阅

873
00:16:40,120 --> 00:16:41,870
更诚实的，我应该说订阅，使神经网络，下

874
00:16:41,870 --> 00:16:41,880
的神经网络

875
00:16:41,880 --> 00:16:43,910
的神经网络，YouTube 的推荐算法是

876
00:16:43,910 --> 00:16:43,920
YouTube的推荐算法是

877
00:16:43,920 --> 00:16:45,710
YouTube的推荐算法相信你想看的内容。

878
00:16:45,710 --> 00:16:45,720
你想看的内容

879
00:16:45,720 --> 00:16:46,910
你想看到这个频道的内容得到

880
00:16:46,910 --> 00:16:46,920
该频道的内容

881
00:16:46,920 --> 00:16:49,430
本频道的内容无论如何都会推荐给您 保持发布

882
00:16:49,430 --> 00:16:49,440
无论如何推荐给您

883
00:16:49,440 --> 00:16:52,030
更多内容 非常感谢大家

884
00:16:52,030 --> 00:16:52,040
非常感谢大家

885
00:16:52,040 --> 00:16:54,110
非常感谢大家在 Patreon 上支持这些视频。

886
00:16:54,110 --> 00:16:54,120
支持 Patreon 上的这些视频，我已经

887
00:16:54,120 --> 00:16:55,509
我的工作进展有点缓慢。

888
00:16:55,509 --> 00:16:55,519
进展有点缓慢

889
00:16:55,519 --> 00:16:57,470
今年夏天，我在 "概率系列 "中的进展有点缓慢，但我在

890
00:16:57,470 --> 00:16:57,480
今年夏天的概率系列，但我

891
00:16:57,480 --> 00:16:59,309
今年夏天的概率系列，但这个项目结束后我又重新投入其中

892
00:16:59,309 --> 00:16:59,319
在这个项目结束后重新投入

893
00:16:59,319 --> 00:17:02,629
在这个项目结束后，我将重新投入到这个项目中，所以赞助商们可以关注我的更新。

894
00:17:02,629 --> 00:17:02,639
读者朋友们，请关注更新

895
00:17:02,639 --> 00:17:04,990
在这里，我有

896
00:17:04,990 --> 00:17:05,000
我有

897
00:17:05,000 --> 00:17:07,230
我请来了 Lea Lee。

898
00:17:07,230 --> 00:17:07,240
和我一起的还有李雅，她的博士论文是

899
00:17:07,240 --> 00:17:08,990
她的博士论文研究的是深度学习的理论方面。

900
00:17:08,990 --> 00:17:09,000
深度学习的理论方面

901
00:17:09,000 --> 00:17:10,270
她目前在一家风险投资公司工作。

902
00:17:10,270 --> 00:17:10,280
目前在一家风险投资公司工作

903
00:17:10,280 --> 00:17:12,470
她目前在一家名为 "amplify Partners "的风险投资公司工作。

904
00:17:12,470 --> 00:17:12,480
他目前在一家名为 "amplify Partners "的风险投资公司工作。

905
00:17:12,480 --> 00:17:14,029
他目前在一家名为 "amplify Partners "的风险投资公司工作。

906
00:17:14,029 --> 00:17:14,039
好心提供了部分资金

907
00:17:14,039 --> 00:17:16,829
他们为本视频提供了部分资金。

908
00:17:16,829 --> 00:17:16,839
我认为我们需要做的一件事是

909
00:17:16,839 --> 00:17:18,750
Leisa 我认为，我们应该快速提出的一点是，这个乙状结肠

910
00:17:18,750 --> 00:17:18,760
应该迅速提出的是这个乙状结肠

911
00:17:18,760 --> 00:17:20,510
我认为我们应该快速提出的一点是，根据我的理解，早期的乙状结肠功能

912
00:17:20,510 --> 00:17:20,520
我早期理解的函数

913
00:17:20,520 --> 00:17:22,309
我的理解是，早期的网络用它来挤压相关的网络。

914
00:17:22,309 --> 00:17:22,319
网络用它来挤压相关的

915
00:17:22,319 --> 00:17:24,189
网络用它将相关的加权和挤压到两者之间的区间内

916
00:17:24,189 --> 00:17:24,199
加权和到 0 和 1 之间的区间

917
00:17:24,199 --> 00:17:26,350
加权总和到 0 和 1 之间的区间，你知道那种动机是

918
00:17:26,350 --> 00:17:26,360
0和1之间的区间。

919
00:17:26,360 --> 00:17:28,270
这种神经元的生物学类比

920
00:17:28,270 --> 00:17:28,280
神经元的生物类比

921
00:17:28,280 --> 00:17:30,590
神经元的这种生物类比要么处于活跃状态，要么正好处于活跃状态

922
00:17:30,590 --> 00:17:30,600
神经元

923
00:17:30,600 --> 00:17:32,669
但现代网络相对较少。

924
00:17:32,669 --> 00:17:32,679
但相对而言，很少有现代网络

925
00:17:32,679 --> 00:17:34,549
但相对而言，很少有现代网络真正使用 sigmoid 了。

926
00:17:34,549 --> 00:17:34,559
但相对而言，很少有现代网络再使用西格莫德（sigmoid）了。

927
00:17:34,559 --> 00:17:37,190
但相对而言，很少有现代网络真正使用 sigmoid 了。

928
00:17:37,190 --> 00:17:37,200
是啊，或者更确切地说

929
00:17:37,200 --> 00:17:39,990
是啊，或者更确切地说，REU似乎更容易训练和REU

930
00:17:39,990 --> 00:17:40,000
似乎更容易训练和康复

931
00:17:40,000 --> 00:17:43,029
是的，或者说，REU 似乎更容易训练，REU 是整流线性单元的缩写。

932
00:17:43,029 --> 00:17:43,039
是的。

933
00:17:43,039 --> 00:17:44,710
是的，REU 代表整流线性单元，是的，就是这种功能

934
00:17:44,710 --> 00:17:44,720
是的

935
00:17:44,720 --> 00:17:47,950
就是这种函数，你只需取零和 a 的最大值即可

936
00:17:47,950 --> 00:17:47,960
只取零和 a 的最大值

937
00:17:47,960 --> 00:17:50,430
取最大值为零和 a，其中 a 由你在书中的解释给出。

938
00:17:50,430 --> 00:17:50,440
是由你在

939
00:17:50,440 --> 00:17:52,470
是由你在视频中解释的内容给出的，而这是一种

940
00:17:52,470 --> 00:17:52,480
你在视频中的解释

941
00:17:52,480 --> 00:17:55,110
这段视频的动机，我认为是部分地

942
00:17:55,110 --> 00:17:55,120
我认为部分原因是

943
00:17:55,120 --> 00:17:59,270
我认为部分动机来自于对神经元的生物类比

944
00:17:59,270 --> 00:17:59,280
神经元的生物学类比

945
00:17:59,280 --> 00:18:01,669
神经元是如何被激活或不被激活的。

946
00:18:01,669 --> 00:18:01,679
所以

947
00:18:01,679 --> 00:18:03,870
神经元要么被激活，要么不被激活，所以如果它通过了某个阈值

948
00:18:03,870 --> 00:18:03,880
如果它通过了某个阈值

949
00:18:03,880 --> 00:18:06,549
如果它通过了某个阈值，它就会是身份函数，但如果它通过了某个阈值，它就会是身份函数。

950
00:18:06,549 --> 00:18:06,559
但如果

951
00:18:06,559 --> 00:18:08,310
但如果没有，它就不会被激活。

952
00:18:08,310 --> 00:18:08,320
那么，它就不会是

953
00:18:08,320 --> 00:18:09,950
那么它就不会被激活，所以它是零，所以它是一种

954
00:18:09,950 --> 00:18:09,960
激活，所以它是零，所以它是一种

955
00:18:09,960 --> 00:18:12,470
激活，所以它是零，所以它是一种使用 sigmoids 的简化，而不是

956
00:18:12,470 --> 00:18:12,480
用四格栅简化并不成功

957
00:18:12,480 --> 00:18:14,070
使用西格莫方法进行简化对训练没有帮助，或者说非常困难

958
00:18:14,070 --> 00:18:14,080
帮助培训还是非常困难

959
00:18:14,080 --> 00:18:16,630
在某些情况下，人们可能会觉得训练很困难。

960
00:18:16,630 --> 00:18:16,640
在某种程度上，训练和训练人

961
00:18:16,640 --> 00:18:19,470
在某种程度上，人们只是试着训练你，而这恰好发生在你身上。

962
00:18:19,470 --> 00:18:19,480
我也是

963
00:18:19,480 --> 00:18:23,029
对这些令人难以置信的人来说，效果很好

964
00:18:23,029 --> 00:18:23,039
效果非常好

965
00:18:23,039 --> 00:18:25,549
对这些令人难以置信的深度神经网络非常有效 好的 谢谢你

966
00:18:25,549 --> 00:18:25,559
深度神经网络

967
00:18:25,559 --> 00:18:27,960
深层神经网络

968
00:18:27,960 --> 00:18:27,970
阿莉西亚

969
00:18:27,970 --> 00:18:41,239
艾莉西亚 [音乐]

